# LLM_ChatApp
# PDF Text Extraction and Chatbot Interaction Web App


file name my.py

install visual studio code

install these libararies
langchain==0.0.154
PyPDF2==3.0.1
python-dotenv==1.0.0
streamlit==1.18.1
faiss-cpu==1.7.4
altair==4.1.0
tiktoken
streamlit-extras


This code is for a Streamlit web application that allows users to upload a PDF file, extract text from it, and then interact with a chatbot powered by an OpenAI language model (LLM). The application is built using various Python libraries, and it provides a user interface for users to ask questions about the content of the uploaded PDF file.

Here's a breakdown of the code and its functionality:

1. **Import Statements:**
   The code starts by importing the required libraries and modules. These include Streamlit for creating the web interface, as well as other libraries like PyPDF2 for working with PDF files, OpenAI for language processing, and more.

2. **Sidebar Contents:**
   The `st.sidebar` section sets up the sidebar of the Streamlit app. It displays a title, a brief description of the app, and the name of the creator.

3. **Load Environment Variables:**
   The `load_dotenv()` function is called to load environment variables if present. However, it seems this function is not used later in the code.

4. **Main Function:**
   The `main()` function is defined, which contains the core logic of the application.

5. **Header and PDF Upload:**
   The header "Chat with PDF" is displayed using `st.header()`. Users are given the option to upload a PDF file using the `st.file_uploader()` function.

6. **Text Extraction:**
   If a PDF file is uploaded, the code uses `PdfReader` from PyPDF2 to extract text from each page of the PDF. The extracted text is split into smaller chunks for processing.

7. **Embeddings and Vector Store:**
   The extracted text chunks are processed using an `OpenAIEmbeddings` instance to obtain embeddings. These embeddings are then used to create a vector store using the `FAISS` library. If a vector store for the PDF file already exists on disk (as a `.pkl` file), it's loaded; otherwise, a new vector store is created and saved to disk.

8. **User Interaction:**
   Users can input a query or question using `st.text_input()`. If a query is provided, the vector store is used to perform similarity search to find relevant documents. The found documents are then passed to a chatbot model for question answering.

9. **Question Answering with Chatbot:**
   A pre-trained OpenAI language model (LLM) is used to generate answers to the user's query. The `load_qa_chain` function loads a question-answering chain based on the LLM. The LLM model generates answers using the provided input documents and the user's question. The answers are displayed using `st.write()`.

The code combines PDF text extraction, embeddings, vector storage, and a chatbot to create a web application that allows users to ask questions about the content of uploaded PDF files and receive answers generated by the OpenAI language model.





Tutorial: https://www.youtube.com/watch?v=RIWbalZ7sTo





